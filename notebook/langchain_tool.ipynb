{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install the required packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-openai in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (0.3.9)\n",
      "Requirement already satisfied: langchain-anthropic in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (0.3.10)\n",
      "Requirement already satisfied: scikit-learn in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (1.6.1)\n",
      "Requirement already satisfied: bs4 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (0.0.2)\n",
      "Requirement already satisfied: pandas in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (2.2.3)\n",
      "Requirement already satisfied: pyarrow in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (19.0.1)\n",
      "Requirement already satisfied: matplotlib in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (3.10.1)\n",
      "Requirement already satisfied: lxml in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (5.3.1)\n",
      "Requirement already satisfied: langgraph in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (0.3.18)\n",
      "Requirement already satisfied: python-dotenv in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (1.0.1)\n",
      "Requirement already satisfied: mcp[cli] in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (1.5.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (0.3.47)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (0.3.18)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.66.3 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain-openai) (1.68.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: anthropic<1,>=0.49.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain-anthropic) (0.49.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain-anthropic) (2.10.6)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from bs4) (4.13.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langgraph) (2.0.21)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langgraph) (0.1.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langgraph) (0.1.58)\n",
      "Requirement already satisfied: anyio>=4.5 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from mcp[cli]) (4.9.0)\n",
      "Requirement already satisfied: httpx>=0.27 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from mcp[cli]) (0.28.1)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from mcp[cli]) (2.2.1)\n",
      "Requirement already satisfied: starlette>=0.27 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from mcp[cli]) (0.46.1)\n",
      "Requirement already satisfied: uvicorn>=0.23.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from mcp[cli]) (0.34.0)\n",
      "Requirement already satisfied: typer>=0.12.4 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from mcp[cli]) (0.15.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from anthropic<1,>=0.49.0->langchain-anthropic) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from anyio>=4.5->mcp[cli]) (3.10)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: certifi in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from httpx>=0.27->mcp[cli]) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from httpx>=0.27->mcp[cli]) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27->mcp[cli]) (0.14.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.66.3->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from typer>=0.12.4->mcp[cli]) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from typer>=0.12.4->mcp[cli]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from typer>=0.12.4->mcp[cli]) (13.9.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from beautifulsoup4->bs4) (2.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.4->mcp[cli]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer>=0.12.4->mcp[cli]) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.12.4->mcp[cli]) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "! source ../.venv/bin/activate\n",
    "! python -m pip install langchain_community langchain-openai langchain-anthropic scikit-learn bs4 pandas pyarrow matplotlib lxml langgraph \"mcp[cli]\" python-dotenv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os\n",
    "import tiktoken\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from langchain_community.document_loaders import RecursiveUrlLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "\n",
    "def count_tokens(text, model=\"cl100k_base\"):\n",
    "    \"\"\"\n",
    "    Count the number of tokens in the text using tiktoken.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to count tokens for\n",
    "        model (str): The tokenizer model to use (default: cl100k_base for GPT-4)\n",
    "        \n",
    "    Returns:\n",
    "        int: Number of tokens in the text\n",
    "    \"\"\"\n",
    "    encoder = tiktoken.get_encoding(model)\n",
    "    return len(encoder.encode(text))\n",
    "\n",
    "def bs4_extractor(html: str) -> str:\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # Target the main article content for Paychex documentation \n",
    "    main_content = soup.find(\"article\", class_=\"md-content__inner\")\n",
    "    \n",
    "    # If found, use that, otherwise fall back to the whole document\n",
    "    content = main_content.get_text() if main_content else soup.text\n",
    "    \n",
    "    # Clean up whitespace\n",
    "    content = re.sub(r\"\\n\\n+\", \"\\n\\n\", content).strip()\n",
    "    \n",
    "    return content\n",
    "\n",
    "def load_paychex_docs():\n",
    "    \"\"\"\n",
    "    Load Paychex documentation from the official website.\n",
    "    \n",
    "    This function:\n",
    "    1. Uses RecursiveUrlLoader to fetch pages from the Paychex website\n",
    "    2. Counts the total documents and tokens loaded\n",
    "    \n",
    "    Returns:\n",
    "        list: A list of Document objects containing the loaded content\n",
    "        list: A list of tokens per document\n",
    "    \"\"\"\n",
    "    print(\"Loading Paychex documentation...\")\n",
    "\n",
    "    # Load the documentation \n",
    "    urls = [\"https://www.paychex.com/payroll\", \n",
    "    ] \n",
    "\n",
    "    docs = []\n",
    "    for url in urls:\n",
    "\n",
    "        loader = RecursiveUrlLoader(\n",
    "            url,\n",
    "            max_depth=5,\n",
    "            extractor=bs4_extractor,\n",
    "        )\n",
    "\n",
    "        # Load documents using lazy loading (memory efficient)\n",
    "        docs_lazy = loader.lazy_load()\n",
    "\n",
    "        # Load documents and track URLs\n",
    "        for d in docs_lazy:\n",
    "            docs.append(d)\n",
    "\n",
    "    print(f\"Loaded {len(docs)} documents from Paychex documentation.\")\n",
    "    print(\"\\nLoaded URLs:\")\n",
    "    for i, doc in enumerate(docs):\n",
    "        print(f\"{i+1}. {doc.metadata.get('source', 'Unknown URL')}\")\n",
    "    \n",
    "    # Count total tokens in documents\n",
    "    total_tokens = 0\n",
    "    tokens_per_doc = []\n",
    "    for doc in docs:\n",
    "        total_tokens += count_tokens(doc.page_content)\n",
    "        tokens_per_doc.append(count_tokens(doc.page_content))\n",
    "    print(f\"Total tokens in loaded documents: {total_tokens}\")\n",
    "    \n",
    "    return docs, tokens_per_doc\n",
    "\n",
    "def save_llms_full(documents):\n",
    "    \"\"\" Save the documents to a file \"\"\"\n",
    "\n",
    "    # Open the output file\n",
    "    output_filename = \"llms_full.txt\"\n",
    "\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        # Write each document\n",
    "        for i, doc in enumerate(documents):\n",
    "            # Get the source (URL) from metadata\n",
    "            source = doc.metadata.get('source', 'Unknown URL')\n",
    "            \n",
    "            # Write the document with proper formatting\n",
    "            f.write(f\"DOCUMENT {i+1}\\n\")\n",
    "            f.write(f\"SOURCE: {source}\\n\")\n",
    "            f.write(\"CONTENT:\\n\")\n",
    "            f.write(doc.page_content)\n",
    "            f.write(\"\\n\\n\" + \"=\"*80 + \"\\n\\n\")\n",
    "\n",
    "    print(f\"Documents concatenated into {output_filename}\")\n",
    "\n",
    "def split_documents(documents):\n",
    "    \"\"\"\n",
    "    Split documents into smaller chunks for improved retrieval.\n",
    "    \n",
    "    This function:\n",
    "    1. Uses RecursiveCharacterTextSplitter with tiktoken to create semantically meaningful chunks\n",
    "    2. Ensures chunks are appropriately sized for embedding and retrieval\n",
    "    3. Counts the resulting chunks and their total tokens\n",
    "    \n",
    "    Args:\n",
    "        documents (list): List of Document objects to split\n",
    "        \n",
    "    Returns:\n",
    "        list: A list of split Document objects\n",
    "    \"\"\"\n",
    "    print(\"Splitting documents...\")\n",
    "    \n",
    "    # Initialize text splitter using tiktoken for accurate token counting\n",
    "    # chunk_size=8,000 creates relatively large chunks for comprehensive context\n",
    "    # chunk_overlap=500 ensures continuity between chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=8000,  \n",
    "        chunk_overlap=500  \n",
    "    )\n",
    "    \n",
    "    # Split documents into chunks\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Created {len(split_docs)} chunks from documents.\")\n",
    "    \n",
    "    # Count total tokens in split documents\n",
    "    total_tokens = 0\n",
    "    for doc in split_docs:\n",
    "        total_tokens += count_tokens(doc.page_content)\n",
    "    \n",
    "    print(f\"Total tokens in split documents: {total_tokens}\")\n",
    "    \n",
    "    return split_docs\n",
    "\n",
    "def create_embeddings():\n",
    "    \"\"\"\n",
    "    Create embeddings using Azure OpenAI\n",
    "    \"\"\"\n",
    "    embeddings = AzureOpenAIEmbeddings( \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\"),\n",
    "        #api_version=os.getenv(\"AZURE_OPENAI_VERSION\"),\n",
    "    )\n",
    "    return embeddings\n",
    "\n",
    "def create_vectorstore(splits):\n",
    "    \"\"\"\n",
    "    Create a vector store from document chunks using SKLearnVectorStore.\n",
    "    \n",
    "    This function:\n",
    "    1. Initializes an embedding model to convert text into vector representations\n",
    "    2. Creates a vector store from the document chunks\n",
    "    \n",
    "    Args:\n",
    "        splits (list): List of split Document objects to embed\n",
    "        \n",
    "    Returns:\n",
    "        SKLearnVectorStore: A vector store containing the embedded documents\n",
    "    \"\"\"\n",
    "    print(\"Creating SKLearnVectorStore...\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create vector store from documents using SKLearn\n",
    "    persist_path = os.getcwd()+\"/sklearn_vectorstore.parquet\"\n",
    "    vectorstore = SKLearnVectorStore.from_documents(\n",
    "        documents=splits,\n",
    "        embedding=create_embeddings(),\n",
    "        persist_path=persist_path   ,\n",
    "        serializer=\"parquet\",\n",
    "    )\n",
    "    print(\"SKLearnVectorStore created successfully.\")\n",
    "    \n",
    "    vectorstore.persist()\n",
    "    print(\"SKLearnVectorStore was persisted to\", persist_path)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Paychex documentation...\n",
      "Loaded 15 documents from Paychex documentation.\n",
      "\n",
      "Loaded URLs:\n",
      "1. https://www.paychex.com/payroll\n",
      "2. https://www.paychex.com/payroll/enterprise-payroll\n",
      "3. https://www.paychex.com/payroll/800-741-6277\n",
      "4. https://www.paychex.com/payroll/888-627-4735\n",
      "5. https://www.paychex.com/payroll/compare-payroll-solutions\n",
      "6. https://www.paychex.com/payroll/866-709-9401\n",
      "7. https://www.paychex.com/payroll/payroll-protection\n",
      "8. https://www.paychex.com/payroll/800-822-8704\n",
      "9. https://www.paychex.com/payroll/833-729-8200\n",
      "10. https://www.paychex.com/payroll/855-263-1021\n",
      "11. https://www.paychex.com/payroll/small-business-payroll\n",
      "12. https://www.paychex.com/payroll/paychex-pre-check\n",
      "13. https://www.paychex.com/payroll/833-299-0168\n",
      "14. https://www.paychex.com/payroll/800-741-6277.\n",
      "15. https://www.paychex.com/payroll/switch-payroll-companies\n",
      "Total tokens in loaded documents: 35553\n",
      "Documents concatenated into llms_full.txt\n",
      "Splitting documents...\n",
      "Created 15 chunks from documents.\n",
      "Total tokens in split documents: 35553\n",
      "Creating SKLearnVectorStore...\n",
      "SKLearnVectorStore created successfully.\n",
      "SKLearnVectorStore was persisted to /Users/visweshwarganesh/Development/MCP/paychex_docs_mcp_tool/notebook/sklearn_vectorstore.parquet\n"
     ]
    }
   ],
   "source": [
    "# Load the documents\n",
    "documents, tokens_per_doc = load_paychex_docs()\n",
    "\n",
    "# Save the documents to a file\n",
    "save_llms_full(documents)\n",
    "\n",
    "# Split the documents\n",
    "split_docs = split_documents(documents)\n",
    "\n",
    "# Create the vector store\n",
    "vectorstore = create_vectorstore(split_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 relevant documents\n",
      "https://www.paychex.com/payroll/payroll-protection\n",
      "Protection Against Payroll Interruptions - Paychex Promise\n",
      "\n",
      "  \n",
      "\n",
      "Skip to main content\n",
      "Skip to footer site map\n",
      "\n",
      " \n",
      "\n",
      "Payroll Services\n",
      "\n",
      "Paychex Promise\n",
      "\n",
      "Payroll Protection and More Through Paychex Promise®\n",
      "Paychex Promise will be offered free of charge to business owners for the first three months of service, and thereafter will be offered as a complete suite of services for a fixed, all-inclusive fee.1 Program and/or any of the services offered as part of Program are subject to eligibility and are v\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "https://www.paychex.com/payroll/payroll-protection\n",
      "Protection Against Payroll Interruptions - Paychex Promise\n",
      "\n",
      "  \n",
      "\n",
      "Skip to main content\n",
      "Skip to footer site map\n",
      "\n",
      " \n",
      "\n",
      "Payroll Services\n",
      "\n",
      "Paychex Promise\n",
      "\n",
      "Payroll Protection and More Through Paychex Promise®\n",
      "Paychex Promise will be offered free of charge to business owners for the first three months of service, and thereafter will be offered as a complete suite of services for a fixed, all-inclusive fee.1 Program and/or any of the services offered as part of Program are subject to eligibility and are v\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "https://www.paychex.com/payroll/payroll-protection\n",
      "Protection Against Payroll Interruptions - Paychex Promise\n",
      "\n",
      "  \n",
      "\n",
      "Skip to main content\n",
      "Skip to footer site map\n",
      "\n",
      " \n",
      "\n",
      "Payroll Services\n",
      "\n",
      "Paychex Promise\n",
      "\n",
      "Payroll Protection and More Through Paychex Promise®\n",
      "Paychex Promise will be offered free of charge to business owners for the first three months of service, and thereafter will be offered as a complete suite of services for a fixed, all-inclusive fee.1 Program and/or any of the services offered as part of Program are subject to eligibility and are v\n",
      "\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create retriever to get relevant documents (k=3 means return top 3 matches)\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "    \n",
    "# Get relevant documents for the query\n",
    "query = \"What are the paychex services ?\"    \n",
    "relevant_docs = retriever.invoke(query)\n",
    "print(f\"Retrieved {len(relevant_docs)} relevant documents\")\n",
    "\n",
    "for d in relevant_docs:\n",
    "    print(d.metadata['source'])\n",
    "    print(d.page_content[0:500])\n",
    "    print(\"\\n--------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def paychex_website_query_tool(query: str):\n",
    "    \"\"\"\n",
    "    Query the Paychex website using a retriever.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query to search the documentation with\n",
    "\n",
    "    Returns:\n",
    "        str: A str of the retrieved documents\n",
    "    \"\"\"\n",
    "    retriever = SKLearnVectorStore(\n",
    "    embedding=create_embeddings(), \n",
    "    persist_path=os.getcwd()+\"/sklearn_vectorstore.parquet\", \n",
    "    serializer=\"parquet\").as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "    relevant_docs = retriever.invoke(query)\n",
    "    print(f\"Retrieved {len(relevant_docs)} relevant documents\")\n",
    "    formatted_context = \"\\n\\n\".join([f\"==DOCUMENT {i+1}==\\n{doc.page_content}\" for i, doc in enumerate(relevant_docs)])\n",
    "    return formatted_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticSerializationError",
     "evalue": "Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPydanticSerializationError\u001b[39m                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Create the messages with system instructions\u001b[39;00m\n\u001b[32m     13\u001b[39m messages = [\n\u001b[32m     14\u001b[39m     {\n\u001b[32m     15\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     }\n\u001b[32m     24\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m message = response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpaychex_website_query_tool\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m message.pretty_print()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:307\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    297\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    298\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    302\u001b[39m     **kwargs: Any,\n\u001b[32m    303\u001b[39m ) -> BaseMessage:\n\u001b[32m    304\u001b[39m     config = ensure_config(config)\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    306\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    317\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:843\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    835\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    836\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    837\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    840\u001b[39m     **kwargs: Any,\n\u001b[32m    841\u001b[39m ) -> LLMResult:\n\u001b[32m    842\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m843\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:683\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    681\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    682\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    689\u001b[39m         )\n\u001b[32m    690\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    691\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:908\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    906\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    907\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m908\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    912\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:925\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    923\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m925\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py:916\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    873\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    911\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    912\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    913\u001b[39m     validate_response_format(response_format)\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._post(\n\u001b[32m    915\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m/chat/completions\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m         body=\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    939\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    942\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    952\u001b[39m         options=make_request_options(\n\u001b[32m    953\u001b[39m             extra_headers=extra_headers, extra_query=extra_query, extra_body=extra_body, timeout=timeout\n\u001b[32m    954\u001b[39m         ),\n\u001b[32m    955\u001b[39m         cast_to=ChatCompletion,\n\u001b[32m    956\u001b[39m         stream=stream \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    957\u001b[39m         stream_cls=Stream[ChatCompletionChunk],\n\u001b[32m    958\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:84\u001b[39m, in \u001b[36mmaybe_transform\u001b[39m\u001b[34m(data, expected_type)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:107\u001b[39m, in \u001b[36mtransform\u001b[39m\u001b[34m(data, expected_type)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\n\u001b[32m     89\u001b[39m     data: _T,\n\u001b[32m     90\u001b[39m     expected_type: \u001b[38;5;28mobject\u001b[39m,\n\u001b[32m     91\u001b[39m ) -> _T:\n\u001b[32m     92\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Transform dictionaries based off of type information from the given type, for example:\u001b[39;00m\n\u001b[32m     93\u001b[39m \n\u001b[32m     94\u001b[39m \u001b[33;03m    ```py\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    105\u001b[39m \u001b[33;03m    It should be noted that the transformations that this function does are not represented in the type system.\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     transformed = \u001b[43m_transform_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(_T, transformed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:195\u001b[39m, in \u001b[36m_transform_recursive\u001b[39m\u001b[34m(data, annotation, inner_type)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_union_type(stripped_type):\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# For union types we run the transformation against all subtypes to ensure that everything is transformed.\u001b[39;00m\n\u001b[32m    191\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# TODO: there may be edge cases where the same normalized field name will transform to two different names\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# in different subtypes.\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subtype \u001b[38;5;129;01min\u001b[39;00m get_args(stripped_type):\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m         data = \u001b[43m_transform_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pydantic.BaseModel):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:169\u001b[39m, in \u001b[36m_transform_recursive\u001b[39m\u001b[34m(data, annotation, inner_type)\u001b[39m\n\u001b[32m    167\u001b[39m origin = get_origin(stripped_type) \u001b[38;5;129;01mor\u001b[39;00m stripped_type\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_typeddict(stripped_type) \u001b[38;5;129;01mand\u001b[39;00m is_mapping(data):\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_transform_typeddict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstripped_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m origin == \u001b[38;5;28mdict\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_mapping(data):\n\u001b[32m    172\u001b[39m     items_type = get_args(stripped_type)[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:253\u001b[39m, in \u001b[36m_transform_typeddict\u001b[39m\u001b[34m(data, expected_type)\u001b[39m\n\u001b[32m    251\u001b[39m         result[key] = value\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m         result[_maybe_transform_key(key, type_)] = \u001b[43m_transform_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:187\u001b[39m, in \u001b[36m_transform_recursive\u001b[39m\u001b[34m(data, annotation, inner_type)\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mobject\u001b[39m, data)\n\u001b[32m    186\u001b[39m     inner_type = extract_type_arg(stripped_type, \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[43m_transform_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_union_type(stripped_type):\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# For union types we run the transformation against all subtypes to ensure that everything is transformed.\u001b[39;00m\n\u001b[32m    191\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# TODO: there may be edge cases where the same normalized field name will transform to two different names\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# in different subtypes.\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subtype \u001b[38;5;129;01min\u001b[39;00m get_args(stripped_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:187\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m cast(\u001b[38;5;28mobject\u001b[39m, data)\n\u001b[32m    186\u001b[39m     inner_type = extract_type_arg(stripped_type, \u001b[32m0\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_transform_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m=\u001b[49m\u001b[43mannotation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minner_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43minner_type\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_union_type(stripped_type):\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# For union types we run the transformation against all subtypes to ensure that everything is transformed.\u001b[39;00m\n\u001b[32m    191\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    192\u001b[39m     \u001b[38;5;66;03m# TODO: there may be edge cases where the same normalized field name will transform to two different names\u001b[39;00m\n\u001b[32m    193\u001b[39m     \u001b[38;5;66;03m# in different subtypes.\u001b[39;00m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subtype \u001b[38;5;129;01min\u001b[39;00m get_args(stripped_type):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_utils/_transform.py:199\u001b[39m, in \u001b[36m_transform_recursive\u001b[39m\u001b[34m(data, annotation, inner_type)\u001b[39m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m    198\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, pydantic.BaseModel):\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mjson\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m annotated_type = _get_annotated_type(annotation)\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m annotated_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/openai/_compat.py:143\u001b[39m, in \u001b[36mmodel_dump\u001b[39m\u001b[34m(model, exclude, exclude_unset, exclude_defaults, warnings, mode)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_dump\u001b[39m(\n\u001b[32m    134\u001b[39m     model: pydantic.BaseModel,\n\u001b[32m    135\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m     mode: Literal[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    141\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m PYDANTIC_V2 \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[33m\"\u001b[39m\u001b[33mmodel_dump\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    144\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    145\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    147\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    148\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# warnings are not supported in Pydantic v1\u001b[39;49;00m\n\u001b[32m    149\u001b[39m \u001b[43m            \u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPYDANTIC_V2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    150\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    152\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdict[str, Any]\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    153\u001b[39m         model.dict(  \u001b[38;5;66;03m# pyright: ignore[reportDeprecated, reportUnnecessaryCast]\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    157\u001b[39m         ),\n\u001b[32m    158\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/MCP/paychex_docs_mcp_tool/.venv/lib/python3.11/site-packages/pydantic/main.py:426\u001b[39m, in \u001b[36mBaseModel.model_dump\u001b[39m\u001b[34m(self, mode, include, exclude, context, by_alias, exclude_unset, exclude_defaults, exclude_none, round_trip, warnings, serialize_as_any)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmodel_dump\u001b[39m(\n\u001b[32m    389\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    390\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    401\u001b[39m     serialize_as_any: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    402\u001b[39m ) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[32m    403\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Usage docs: https://docs.pydantic.dev/2.10/concepts/serialization/#modelmodel_dump\u001b[39;00m\n\u001b[32m    404\u001b[39m \n\u001b[32m    405\u001b[39m \u001b[33;03m    Generate a dictionary representation of the model, optionally specifying which fields to include or exclude.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    424\u001b[39m \u001b[33;03m        A dictionary representation of the model.\u001b[39;00m\n\u001b[32m    425\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m426\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_serializer__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m        \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m        \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_unset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_defaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m        \u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m=\u001b[49m\u001b[43mround_trip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarnings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserialize_as_any\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mPydanticSerializationError\u001b[39m: Unable to serialize unknown type: <class 'pydantic._internal._model_construction.ModelMetaclass'>"
     ]
    }
   ],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),  # Your GPT-4 deployment name\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-11-20\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "# Create the messages with system instructions\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are a helpful assistant that can answer questions about the Paychex website. \n",
    "        Use the provided tools to search the Paychex documentation when needed.\n",
    "        If you don't know the answer, say \"I don't know\".\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What are the paychex services?\"\n",
    "    }\n",
    "]\n",
    " \n",
    "message = response = llm.invoke(messages, tools=[paychex_website_query_tool])\n",
    "\n",
    "message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
